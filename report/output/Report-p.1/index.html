<!DOCTYPE html>
<!--suppress ALL -->
<html lang="en">
<head>
    <meta name="generator" content="Quarkdown">
    <meta charset="UTF-8">
    <meta name="author" content="Mounir Samite">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Report p.1</title>
    <script src="./script/quarkdown.js"></script>
    <script>const capabilities = window.quarkdownCapabilities</script>
    <script>window.PagedConfig = {auto: false};</script>
    <script src="https://unpkg.com/pagedjs@0.4.3/dist/paged.polyfill.js"></script>
    <link href='https://unpkg.com/boxicons@2.1.4/css/boxicons.min.css' rel='stylesheet'>
    <link rel="stylesheet" href="./theme/theme.css">
    <script src="https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.min.js"></script>
    <script>capabilities.mermaid = true;</script>

    <style>

        body {
        }

        .page-break {
            break-before: always;
        }

        .quarkdown-plain .page-break {
            break-before: avoid;
            break-after: avoid;
        }

        body.quarkdown-plain.quarkdown-plain {
        }

        body.quarkdown-slides.quarkdown-slides .reveal {
            width: 210.0mm;
            height: 297.0mm;
        }

        @page {
            size: 210.0mm 297.0mm;
        }

        p {
        }
    </style>
    <script>
        const doc = new PagedDocument();
        prepare(doc);
    </script>
</head>
<body class="quarkdown quarkdown-paged">
<div class="page-margin-content page-margin-bottom-center" data-on-left-page="bottom-center" data-on-right-page="bottom-center"><p><span class="current-page-number">-</span> / <span class="total-page-number">-</span></p></div><div class="container fullwidth" style="justify-items: center; text-align: center;"><h1 id="report-p1" data-decorative="">Report p.1</h1><p>Mounir Samite 2026</p></div><hr /><div class="page-break" data-hidden=""></div><h1 id="table-of-contents">Table of Contents</h1><nav data-role="table-of-contents"><ol><li data-location="1"><a href="#problem-analisys">Problem analisys</a><ol><li data-location="1.1"><a href="#decomposition-strategy">Decomposition strategy</a></li><li data-location="1.2"><a href="#coordination-and-synchronization-challenges">Coordination and synchronization challenges</a></li></ol></li><li data-location="2"><a href="#solution-strategy-and-architecture">Solution strategy and architecture</a><ol><li data-location="2.1"><a href="#high-level-architecture">High-level architecture</a></li><li data-location="2.2"><a href="#thread-based-approach">Thread based approach</a></li><li data-location="2.3"><a href="#virtual-threads">Virtual Threads</a></li><li data-location="2.4"><a href="#task-based-approach">Task based approach</a></li><li data-location="2.5"><a href="#async-event-approach">Async event approach</a></li><li data-location="2.6"><a href="#reactive-programming-approach">Reactive programming approach</a></li><li data-location="2.7"><a href="#_"></a></li></ol></li></ol></nav><p></p><div class="page-break" data-hidden=""></div><h1 id="problem-analisys" data-location="1">Problem analisys</h1><p>The problem presents a computational task that is inherently parallelizable due to the independent nature of processing individual pdf files. The core challenge involves recursively traversing a directory structure, identifying pdf files, extracting text content, and searching for a specific word while maintaining accurate counts and providing real-time progress updates through a GUI.</p><h2 id="decomposition-strategy" data-location="1.1">Decomposition strategy</h2><p>The problem can be decomposed along two primary dimensions: task decomposition and data decomposition.
Task decomposition involves breaking down the workflow into distinct
operations:</p><ul><li>directory traversal</li><li>file identification</li><li>pdf text extraction</li><li>word matching</li><li>result aggregation</li></ul><p>While data decomposition focuses on partitioning the set of pdf files
into chunks that can be processed concurrently.
The initial sequential implementation revealed that pdf files constitute
independent units of work, as analyzing one file does not depend on the
results of analyzing another, making them ideal candidates for parallel processing.</p><h2 id="coordination-and-synchronization-challenges" data-location="1.2">Coordination and synchronization challenges</h2><p>Despite the high degree of independence, several coordination
points require careful synchronization.
The shared counters (total files analyzed, PDFs found,
PDFs containing the target word) represent critical sections
that must be protected against race conditions when multiple threads
update them concurrently.
Additionally, the GUI updates must be coordinated to ensure
consistent and accurate display of progress without overwhelming
the event dispatch thread.
The start, stop, suspend, resume controls introduce additional
complexity, requiring mechanisms to pause and resume worker threads
cooperatively while maintaining system state consistency.</p><div class="page-break" data-hidden=""></div><h1 id="solution-strategy-and-architecture" data-location="2">Solution strategy and architecture</h1><h2 id="high-level-architecture" data-location="2.1">High-level architecture</h2><p>The project adopts a modular architecture that combines the Model-View-Controller 
pattern with the Strategy pattern to accommodate six distinct concurrency approaches while
maintaining code reusability and separation of concerns.</p><figure><pre class="mermaid fill-height">flowchart TD
    subgraph MVC[&quot;MVC Pattern&quot;]
        V[SearchView]
        C[SearchController]
        M[SearchModel]
    end
    
    subgraph Strategies[&quot;Strategy Pattern&quot;]
        S[PdfWordSearcher Interface]
        T1[Thread]
        T2[Virtual Thread]
        T3[Task Based]
        T4[Async Event]
        T5[Reactive]
        T6[Actor]
    end
    
    E[ExtractionEvent]
    
    V --&gt; C
    C --&gt; M
    M --&gt; V
    C --&gt; S
    
    S --&gt; T1
    S --&gt; T2
    S --&gt; T3
    S --&gt; T4
    S --&gt; T5
    S --&gt; T6
    
    T1 --&gt; E
    T2 --&gt; E
    T3 --&gt; E
    T4 --&gt; E
    T5 --&gt; E
    T6 --&gt; E
    
    E --&gt; M</pre></figure><h3 id="core-architecture-components" data-location="2.1.1">Core architecture components</h3><p>The application&rsquo;s structure consists of three primary MVC
components that remain consistent across all concurrency implementations:</p><ul><li><strong>SearchModel</strong>: Encapsulates the application state, including counters for analyzed files, PDF files found, and matches containing the target word. This model serves as the single source of truth and notifies observers of state changes</li><li><strong>SearchView</strong>: Provides the graphical user interface with input fields for directory path and search word, control buttons (start/stop/suspend/resume), and output boxes displaying real-time progress</li><li><strong>SearchController</strong>: Mediates between the view and model, handling user interactions and delegating work to the appropriate concurrency strategy implementation</li></ul><p>The ModelObserver interface implements the Observer pattern, enabling the view to react to model state changes without tight coupling, ensuring that GUI updates remain synchronized with the underlying computational progress.</p><h3 id="strategy-pattern" data-location="2.1.2">Strategy pattern</h3><p>The core of this architecture lies in the strategies package,
which encapsulates each concurrency approach as an interchangeable implementation
of the PdfWordSearcher interface.
This design decision allows the controller to remain agnostic to the underlying concurrency
mechanism while supporting six fundamentally different approaches:</p><ul><li><strong>thread</strong>: Implements traditional multithreaded approach using custom monitors and thread pools</li><li><strong>virtual threads</strong>: Leverages Java virtual threads for lightweight concurrency</li><li><strong>task based</strong>: Utilizes Java Executors and Fork/Join framework with task decomposition</li><li><strong>async event</strong>: Employs Vertx event-loop architecture for asynchronous processing</li><li><strong>reactive programming</strong>: Applies RxJava reactive streams for data flow management</li><li><strong>actors</strong>: Uses Akka actor model for message-passing concurrency</li></ul><p>Each strategy package contains specialized components tailored to its concurrency model while adhering to a common interface,
ensuring seamless swapping between implementations.</p><h3 id="event-system" data-location="2.1.3">Event system</h3><p>The events package defines a unified event model (ExtractionEvent and ExtractionEventType)
that enables consistent communication between Model, Controller and View.
This abstraction allows different strategies to report progress using the same event types
regardless of their internal implementation details.
â€‹</p><h3 id="supporting-infrastructure" data-location="2.1.4">Supporting infrastructure</h3><p>The project structure includes dedicated components for testing and validation:</p><ul><li>generator: Contains scripts and sample PDFs for creating test datasets with varying file counts and directory depths</li><li>pdfs: Houses multiple test scenarios ranging from small sets (3-10 files) to large-scale tests (50,000+ files) with both flat and recursive directory structures</li><li>jpf-workspace: Provides Java PathFinder integration for formal verification of concurrent properties in the thread based implementation</li></ul><p>This organizational structure ensures that each concurrency strategy can be developed,
tested, and analyzed independently while sharing common infrastructure components,
facilitating comparative performance analysis across all six approaches.</p><h2 id="thread-based-approach" data-location="2.2">Thread based approach</h2><p>The thread based implementation leverages traditional multithreading
principles with custom monitor synchronization to achieve optimal CPU
utilization while maintaining strict control over concurrency mechanisms.</p><figure><pre class="mermaid fill-height">flowchart TD
    Start([PDF Files List])
    Split{Partition N=CPU+1}
    W1[Worker 1 Chunk 1]
    W2[Worker 2 Chunk 2]
    W3[Worker N Chunk N]
    P1[Process PDFs Extract Match]
    P2[Process PDFs Extract Match]
    P3[Process PDFs Extract Match]
    U1[Update Model: increment pdfsWithWord]
    U2[Update Model: increment pdfsWithWord]
    U3[Update Model: increment pdfsWithWord]
    M((Monitor))
    Wait[Output Thread await]
    Signal[signal complete]
    Result([Final Count + Time])
    
    Start --&gt; Split
    Split --&gt; W1
    Split --&gt; W2
    Split --&gt; W3
    W1 --&gt; P1
    W2 --&gt; P2
    W3 --&gt; P3
    P1 --&gt; U1
    P2 --&gt; U2
    P3 --&gt; U3
    U1 --&gt; M
    U2 --&gt; M
    U3 --&gt; M
    M --&gt; Wait
    Wait --&gt; Signal
    Signal --&gt; Result</pre></figure><h3 id="thread-pool-size-strategy" data-location="2.2.1">Thread pool size strategy</h3><p>The solution dynamically determines the optimal number of worker threads based
on available CPU resources using the formula Nthreads = Ncpu + 1,
where Ncpu is obtained via <span class="codespan-content"><code>Runtime.getRuntime().availableProcessors()</code></span>.
This approach follows the established heuristic that a system with N processors
achieves optimal utilization with N+1 threads, accounting for potential I/O blocking during
PDF file operations.
When the number of PDF files is smaller than available CPUs,
the thread count adapts accordingly to avoid unnecessary thread creation overhead.</p><h3 id="work-partitioning-and-distribution" data-location="2.2.2">Work partitioning and distribution</h3><p>The ThreadPoolSearch class divides the list of PDF files into equal-sized chunks using a step-based partitioning strategy: step = numFiles / Nthreads.
Each Worker thread receives a contiguous range defined by start and end indices, processing files
independently without inter-worker communication. The final worker handles any remaining files due to integer division, ensuring all PDFs are processed.</p><h3 id="monitor-based-coordination" data-location="2.2.3">Monitor-Based Coordination</h3><p>The custom monitor class implements a synchronization mechanism using ReentrantLock
and Condition variables from java.util.concurrent.locks, adhering to the assignment
constraint of using only low-level concurrent utilities for monitor implementation.
The monitor maintains two critical pieces of state:</p><ul><li>count: Accumulates the total number of PDFs containing the target word across all workers.</li><li>numFiles: Tracks remaining unprocessed files, decremented as workers complete their chunks.</li></ul><p>Workers call <span class="codespan-content"><code>updateFoundFiles(analyzedFiles, filesFound)</code></span> upon completing their assigned chunk, which atomically updates both counters under mutex protection. When the last worker finishes (numFiles == 0),
the monitor signals the waiting Output thread via the workersFinished condition variable.</p><h3 id="worker-thread-implementation" data-location="2.2.4">Worker thread implementation</h3><p>Each worker thread <span class="codespan-content"><code>extends Thread</code></span> and processes its assigned file range by iterating through
PDF files, extracting text using Apache PDFBox&rsquo;s PDFTextStripper, and performing string matching.
The worker immediately updates the shared SearchModel when a match is found via <span class="codespan-content"><code>model.incCountPdfFilesWithWord()</code></span>,
enabling real-time updates.
After processing all assigned files, the worker reports its results to the monitor,
decoupling individual progress updates from final aggregation.</p><h3 id="output-thread-and-results-collection" data-location="2.2.5">Output thread and results collection</h3><p>The Output thread implements a separate waiting mechanism that blocks on the monitor&rsquo;s get()
method until all workers signal completion. This design separates result collection from
computation, allowing the main thread to remain responsive while workers execute in parallel.
The output thread also measures total execution time from job start to completion,
providing performance metrics.</p><figure><pre class="mermaid fill-height">classDiagram
    class PdfWordSearcher {
        &lt;&lt;interface&gt;&gt;
        +extractText(List~File~ pdfs, String word, SearchModel model)
    }
    
    class ThreadPoolSearch {
        +extractText(List~File~ files, String word, SearchModel model)
    }
    
    class Monitor {
        -int count
        -Lock mutex
        -Condition workersFinished
        -int numFiles
        -SearchModel model
        +Monitor(int numFiles, SearchModel model)
        +updateFoundFiles(int analyzedFiles, int filesFound)
        +get() int
    }
    
    class Worker {
        -Monitor cell
        -List~File~ files
        -int start
        -int end
        -String searchedWord
        -SearchModel model
        +Worker(Monitor cell, int start, int end, List~File~ files, String word, SearchModel model)
        +run()
        -containsWord(File pdf, String word) boolean
    }
    
    class Output {
        -Monitor cell
        -long startTime
        +Output(Monitor cell, long startTime)
        +run()
    }
    
    class SearchModel {
        +incCountPdfFilesWithWord()
    }
    
    PdfWordSearcher &lt;|.. ThreadPoolSearch
    ThreadPoolSearch ..&gt; Monitor : creates
    ThreadPoolSearch ..&gt; Worker : creates
    ThreadPoolSearch ..&gt; Output : creates
    Worker --&gt; Monitor : updates
    Worker --&gt; SearchModel : updates
    Output --&gt; Monitor : waits on
    Monitor --&gt; SearchModel : uses</pre></figure><div class="page-break" data-hidden=""></div><p></p><h2 id="virtual-threads" data-location="2.3">Virtual Threads</h2><p>The virtual thread implementation adopts a virtual thread per file strategy where each
PDF is processed by its own virtual thread.</p><h3 id="implementation-structure" data-location="2.3.1">Implementation Structure</h3><p>The solution creates a <strong>monitor</strong> to coordinate all virtual threads, initialized with the total number of files to process. A <strong>virtual thread executor</strong> manages the lifecycle of all worker threads automatically through Java&rsquo;s resource management. Additionally, a separate <strong>output thread</strong> is created but held in reserve until all worker threads begin their execution.</p><p>The processing logic iterates through the entire list of PDF files and submits each one as an independent task to the executor. For each file, a new virtual thread is spawned with a unique identifier for debugging purposes. Each virtual thread independently loads its assigned PDF, extracts the text content, searches for the target word, and reports whether a match was found to the shared monitor.
Once all tasks are submitted, the output thread begins execution and the main program waits for it to complete before returning</p><h3 id="monitor-synchronization" data-location="2.3.2">Monitor synchronization</h3><p>The monitor uses explicit lock and condition variable mechanisms rather than traditional synchronized blocks, which is essential to prevent virtual threads from being pinned to their carrier threads during blocking operations. When each thread completes processing its file, it calls a method that updates the match counter if the word was found, decrements the remaining work counter, and signals when all files have been processed. The output thread blocks on the monitor until it receives the completion signal, then retrieves and returns the final count.</p><p>During the computation, every time a new file contains the word, the model is updated.</p><p>This architecture exploits the lightweight nature of virtual threads to achieve massive parallelism, creating as many virtual threads as there are PDF files, without overwhelming system resources.</p><figure><pre class="mermaid fill-height">classDiagram
class PdfWordSearcher {
    &lt;&lt;interface&gt;&gt;
    +extractText(List~File~ pdfs, String word, SearchModel model)
}

class VirtualThreadSearcher {
    +extractText(List~File~ files, String word, SearchModel model)
    -containsWord(File pdf, String word) boolean
}

class Monitor {
    -int count
    -Lock mutex
    -Condition workersFinished
    -int numFiles
    -SearchModel model
    +Monitor(int numFiles, SearchModel model)
    +foundWord(boolean found)
    +get() int
}

class VirtualThreadExecutor {
    &lt;&lt;executor&gt;&gt;
    +submit(Runnable task)
    +close()
}

class WorkerThread {
    &lt;&lt;virtual thread&gt;&gt;
    +start(Runnable task)
}

class OutputThread {
    &lt;&lt;virtual thread&gt;&gt;
    +run()
}

class SearchModel {
    +setCountPdfFilesWithWord(int count)
}

PdfWordSearcher &lt;|.. VirtualThreadSearcher
VirtualThreadSearcher ..&gt; Monitor : creates
VirtualThreadSearcher ..&gt; VirtualThreadExecutor : uses
VirtualThreadSearcher ..&gt; OutputThread : creates
VirtualThreadExecutor ..&gt; WorkerThread : spawns N threads
WorkerThread --&gt; Monitor : reports to
WorkerThread --&gt; SearchModel : updates
OutputThread --&gt; Monitor : waits on
Monitor --&gt; SearchModel : updates</pre></figure><div class="page-break" data-hidden=""></div><h2 id="task-based-approach" data-location="2.4">Task based approach</h2><p>The task-based implementation uses Java&rsquo;s ForkJoin framework to decompose the problem hierarchically, mirroring the recursive structure of the directory tree itself.</p><h3 id="hierachical-task-decomposition" data-location="2.4.1">Hierachical task decomposition</h3><p>The solution begins by constructing a complete representation of the directory structure before processing begins. The tree representation recursively captures subdirectories and PDF files at each level, creating a hierarchical data structure that mirrors the file system. This upfront construction enables the ForkJoin framework to understand the complete workload structure and optimize task distribution.</p><p>The tree builder traverses each directory, classifying entries as either subdirectories (which are recursively processed) or PDF files (which are collected as leaf nodes). This separation allows the framework to spawn different task types: directory scanning tasks for structural traversal and word search tasks for actual file processing.</p><h3 id="forkjoin-execution-model" data-location="2.4.2">ForkJoin execution model</h3><p>The coordinator creates a ForkJoin pool and submits the root in the directory task, which initiates the recursive decomposition. Each directory scanning task examines its assigned directory node and performs a two phase forking strategy.</p><p>In the first phase, the task creates and forks child directory tasks for each subdirectory, enabling parallel exploration of the directory tree. In the second phase, it creates and forks word search tasks for each PDF file in the current directory. All forked tasks are collected in a list for subsequent joining.</p><p>After forking all subtasks, the directory task enters a joining phase where it waits for each child task to complete and accumulates their results. This fork-join pattern creates a recursive decomposition where work is divided (forked) down the tree and results are aggregated (joined) back up.</p><h3 id="leaf-word-search-task-process" data-location="2.4.3">Leaf (word search) task process</h3><p>Word search tasks represent the atomic units of computation in this approach. Each task receives a single PDF file reference, extracts its text content, searches for the target word, and returns either 1 for a match or 0 for no match. When a match is found, the task immediately updates the shared model to provide constant UI feedback</p><figure><pre class="mermaid fill-height">flowchart TD
Start[ForkJoinSearcher] --&gt; Build[Build DirectoryTree&lt;br/&gt;from root directory]
Build --&gt; Pool[Create ForkJoinPool]
Pool --&gt; RootTask[DirectoryScanTask&lt;br/&gt;Root Directory]

RootTask --&gt; Fork1{Fork Phase}

Fork1 --&gt; SubDir1[DirectoryScanTask&lt;br/&gt;Subdirectory 1]
Fork1 --&gt; SubDir2[DirectoryScanTask&lt;br/&gt;Subdirectory 2]
Fork1 --&gt; PDF1[WordSearchTask&lt;br/&gt;PDF 1]
Fork1 --&gt; PDF2[WordSearchTask&lt;br/&gt;PDF 2]
Fork1 --&gt; PDF3[WordSearchTask&lt;br/&gt;PDF 3]

SubDir1 --&gt; Fork2{Fork Phase}
Fork2 --&gt; PDF4[WordSearchTask&lt;br/&gt;PDF 4]
Fork2 --&gt; PDF5[WordSearchTask&lt;br/&gt;PDF 5]

SubDir2 --&gt; Fork3{Fork Phase}
Fork3 --&gt; PDF6[WordSearchTask&lt;br/&gt;PDF 6]
Fork3 --&gt; PDF7[WordSearchTask&lt;br/&gt;PDF 7]

PDF1 --&gt; R1[Return 0/1]
PDF2 --&gt; R2[Return 0/1]
PDF3 --&gt; R3[Return 0/1]
PDF4 --&gt; R4[Return 0/1]
PDF5 --&gt; R5[Return 0/1]
PDF6 --&gt; R6[Return 0/1]
PDF7 --&gt; R7[Return 0/1]

R4 --&gt; Join2[Join Results]
R5 --&gt; Join2
Join2 --&gt; SubDir1Result[Sum]

R6 --&gt; Join3[Join Results]
R7 --&gt; Join3
Join3 --&gt; SubDir2Result[Sum]

R1 --&gt; Join1[Join All Results]
R2 --&gt; Join1
R3 --&gt; Join1
SubDir1Result --&gt; Join1
SubDir2Result --&gt; Join1

Join1 --&gt; Final[Total Count]</pre></figure><div class="page-break" data-hidden=""></div><h2 id="async-event-approach" data-location="2.5">Async event approach</h2><p>The async event implementation uses the Vert.x framework, which provides an event loop architecture for non-blocking asynchronous processing.</p><h3 id="verticle-based-architecture" data-location="2.5.1">Verticle based architecture</h3><p>The solution creates a custom verticle, which serves as the deployable unit of concurrent execution in Vert.x. The main searcher class configures a Vert.x instance with a worker pool sized to match available CPU cores, then deploys the PDF search verticle onto this runtime.
The verticle encapsulates the entire search logic within its methods, receiving the list of PDF files, target word, and model reference through its constructor. When the verticle starts, it initiates the asynchronous processing pipeline.</p><h3 id="event-loop-and-worker-pool" data-location="2.5.2">Event loop and worker pool</h3><p>For each PDF file, the verticle submits a blocking task that extracts text and searches for the target word. These tasks execute on worker threads from the pool, preventing the event loop from blocking. Each blocking operation immediately returns a Future object representing the eventual completion of that task.</p><h3 id="future-composition-and-aggregation" data-location="2.5.3">Future Composition and aggregation</h3><p>All individual file processing futures are collected into a list as they are created. The framework then composes these futures using a composite future that completes only when all individual futures have finished.
When the composite future completes, a mapping operation iterates through all results, summing the match counts and updating the model with the final total. This composition is declarative, with success handlers attached to process results when they become available.</p><h3 id="non-blocking-result-handling" data-location="2.5.4">Non blocking result handling</h3><p>The result handling follows a callback based pattern where success handlers are registered to execute when futures complete. This approach ensures the event loop remains free to handle other events while waiting for blocking operations to finish. Timing information is captured at the start of processing and compared against completion time to measure total execution duration.</p><figure><pre class="mermaid fill-height">flowchart TD
Start[VertxAsyncSearcher] --&gt; Config[Configure Vert.x&lt;br/&gt;Worker Pool Size = CPU cores]
Config --&gt; Deploy[Deploy PdfSearchVerticle]

Deploy --&gt; EventLoop[Event Loop Thread]

EventLoop --&gt; Submit1[Submit Blocking Task&lt;br/&gt;PDF 1]
EventLoop --&gt; Submit2[Submit Blocking Task&lt;br/&gt;PDF 2]
EventLoop --&gt; Submit3[Submit Blocking Task&lt;br/&gt;PDF N]

Submit1 --&gt; Future1[Future 1]
Submit2 --&gt; Future2[Future 2]
Submit3 --&gt; FutureN[Future N]

Future1 --&gt; Worker1[Worker Thread 1&lt;br/&gt;Extract &amp; Search PDF 1]
Future2 --&gt; Worker2[Worker Thread 2&lt;br/&gt;Extract &amp; Search PDF 2]
FutureN --&gt; WorkerN[Worker Thread N&lt;br/&gt;Extract &amp; Search PDF N]

Worker1 --&gt; Update1[Update Model&lt;br/&gt;if match found]
Worker2 --&gt; Update2[Update Model&lt;br/&gt;if match found]
WorkerN --&gt; UpdateN[Update Model&lt;br/&gt;if match found]

Update1 --&gt; Result1[Return 0/1]
Update2 --&gt; Result2[Return 0/1]
UpdateN --&gt; ResultN[Return 0/1]

Result1 --&gt; Complete1[Future 1 Completes]
Result2 --&gt; Complete2[Future 2 Completes]
ResultN --&gt; CompleteN[Future N Completes]

Complete1 --&gt; Composite[Future.all&lt;br/&gt;Composite Future]
Complete2 --&gt; Composite
CompleteN --&gt; Composite

Composite --&gt; AllComplete{All Futures&lt;br/&gt;Complete?}
AllComplete --&gt;|Yes| Map[Sum all results]
Map --&gt; Success[Success Handler&lt;br/&gt;Print total &amp; time]

AllComplete --&gt;|No| Wait[Event Loop Waits]
Wait -.-&gt; Composite</pre></figure><div class="page-break" data-hidden=""></div><h2 id="reactive-programming-approach" data-location="2.6">Reactive programming approach</h2><p>The reactive programming implementation uses RxJava to model PDF processing as a data stream.</p><h3 id="hot-observable-stream-creation" data-location="2.6.1">Hot observable stream creation</h3><p>The solution creates a hot observable stream by first defining a flowable source that emits processing results. The flowable is constructed using a custom emitter that iterates through all PDF files sequentially, processing each one and emitting integer values: 1 for files containing the target word, 0 otherwise.
The emitter handles the complete lifecycle: it processes all files in a loop, emits results as they become available, signals completion when all files are processed, and propagates any errors encountered during execution. A <strong>buffer backpressure strategy</strong> is configured to handle situations where the consumer cannot keep up with emitted items.
After creating the flowable, it is converted to a hot observable using the publish operator and immediately connected.</p><h3 id="flow-control" data-location="2.6.2">flow control</h3><p>The main processing pipeline applies a sequence of reactive operators to transform the stream. First, a backpressure buffer with a capacity of 5,000 items protects against overflow when the producer emits faster than the consumer can process.
The reduce operator aggregates all emitted values into a single sum, effectively counting total matches across all PDFs. This reduction happens asynchronously as values flow through the stream.
The pipeline concludes with a blocking subscription that waits for the final reduced value, executing success and error handlers when the stream completes.</p><p>Unlike the final aggregation performed by the reduce operator, the model is updated immediately within the emitter loop whenever a match is found. This update strategy provides real-time UI feedback through incremental model updates while the reduce operator handles final result computation.</p><figure><pre class="mermaid fill-height">flowchart TD
    Start[RxJavaSearcher] --&gt; Create[Create Flowable&lt;br/&gt;with Custom Emitter]
    
    Create --&gt; Loop[Iterate PDF Files&lt;br/&gt;in Emitter]
    
    Loop --&gt; Process1[Process PDF 1&lt;br/&gt;containsWord]
    Loop --&gt; Process2[Process PDF 2&lt;br/&gt;containsWord]
    Loop --&gt; ProcessN[Process PDF N&lt;br/&gt;containsWord]
    
    Process1 --&gt; Check1{Match Found?}
    Process2 --&gt; Check2{Match Found?}
    ProcessN --&gt; CheckN{Match Found?}
    
    Check1 --&gt;|Yes| Update1[Update Model]
    Check2 --&gt;|Yes| Update2[Update Model]
    CheckN --&gt;|Yes| UpdateN[Update Model]
    
    Check1 --&gt;|Always| Emit1[Emit 1 or 0]
    Check2 --&gt;|Always| Emit2[Emit 1 or 0]
    CheckN --&gt;|Always| EmitN[Emit 1 or 0]
    
    Update1 --&gt; Emit1
    Update2 --&gt; Emit2
    UpdateN --&gt; EmitN
    
    Emit1 --&gt; Hot[publish + connect&lt;br/&gt;Hot Observable]
    Emit2 --&gt; Hot
    EmitN --&gt; Hot
    
    Hot --&gt; Buffer[onBackpressureBuffer&lt;br/&gt;capacity: 5000]
    Buffer --&gt; Reduce[reduce&lt;br/&gt;sum all values]
    Reduce --&gt; Schedule[observeOn&lt;br/&gt;Schedulers.computation]
    Schedule --&gt; Subscribe[blockingSubscribe&lt;br/&gt;wait for result]
    Subscribe --&gt; Final[Print Total Count&lt;br/&gt;+ Time]</pre></figure><div class="page-break" data-hidden=""></div><h2 id="_" data-location="2.7"></h2>
</body>
</html>