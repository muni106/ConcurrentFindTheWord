<!DOCTYPE html>
<!--suppress ALL -->
<html lang="en">
<head>
    <meta name="generator" content="Quarkdown">
    <meta charset="UTF-8">
    <meta name="author" content="Mounir Samite">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Report p.1</title>
    <script src="./script/quarkdown.js"></script>
    <script>const capabilities = window.quarkdownCapabilities</script>
    <script>window.PagedConfig = {auto: false};</script>
    <script src="https://unpkg.com/pagedjs@0.4.3/dist/paged.polyfill.js"></script>
    <link href='https://unpkg.com/boxicons@2.1.4/css/boxicons.min.css' rel='stylesheet'>
    <link rel="stylesheet" href="./theme/theme.css">
    <script src="https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.min.js"></script>
    <script>capabilities.mermaid = true;</script>

    <style>

        body {
        }

        .page-break {
            break-before: always;
        }

        .quarkdown-plain .page-break {
            break-before: avoid;
            break-after: avoid;
        }

        body.quarkdown-plain.quarkdown-plain {
        }

        body.quarkdown-slides.quarkdown-slides .reveal {
            width: 210.0mm;
            height: 297.0mm;
        }

        @page {
            size: 210.0mm 297.0mm;
        }

        p {
        }
    </style>
    <script>
        const doc = new PagedDocument();
        prepare(doc);
    </script>
</head>
<body class="quarkdown quarkdown-paged">
<div class="page-margin-content page-margin-bottom-center" data-on-left-page="bottom-center" data-on-right-page="bottom-center"><p><span class="current-page-number">-</span> / <span class="total-page-number">-</span></p></div><div class="container fullwidth" style="justify-items: center; text-align: center;"><h1 id="report-p1" data-decorative="">Report p.1</h1><p>Mounir Samite 2026</p></div><hr /><div class="page-break" data-hidden=""></div><h1 id="table-of-contents">Table of Contents</h1><nav data-role="table-of-contents"><ol><li data-location="1"><a href="#problem-analysis">Problem analysis</a><ol><li data-location="1.1"><a href="#decomposition-strategy">Decomposition strategy</a></li><li data-location="1.2"><a href="#coordination-and-synchronization-challenges">Coordination and synchronization challenges</a></li></ol></li><li data-location="2"><a href="#solution-strategy-and-architecture">Solution strategy and architecture</a><ol><li data-location="2.1"><a href="#highlevel-architecture">Highlevel architecture</a></li><li data-location="2.2"><a href="#thread-based-approach">Thread based approach</a></li><li data-location="2.3"><a href="#virtual-threads">Virtual Threads</a></li><li data-location="2.4"><a href="#task-based-approach">Task based approach</a></li><li data-location="2.5"><a href="#async-event-approach">Async event approach</a></li><li data-location="2.6"><a href="#reactive-programming-approach">Reactive programming approach</a></li><li data-location="2.7"><a href="#actor-approach">Actor approach</a></li></ol></li><li data-location="3"><a href="#performance-and-correctness">Performance and correctness</a><ol><li data-location="3.1"><a href="#benchmark-methodology">Benchmark methodology</a></li><li data-location="3.2"><a href="#results">Results</a></li><li data-location="3.3"><a href="#model-checking">Model Checking</a></li></ol></li></ol></nav><p></p><div class="page-break" data-hidden=""></div><h1 id="problem-analysis" data-location="1">Problem analysis</h1><p>The problem presents a computational task that is inherently parallelizable due to the independent nature of processing individual pdf files. The core challenge involves recursively traversing a directory structure, identifying pdf files, extracting text content, and searching for a specific word while maintaining accurate counts and providing real-time progress updates through a gui.</p><h2 id="decomposition-strategy" data-location="1.1">Decomposition strategy</h2><p>The problem can be decomposed along two primary dimensions: task decomposition and data decomposition.
Task decomposition involves breaking down the workflow into distinct
operations:</p><ul><li>directory traversal</li><li>file identification</li><li>pdf text extraction</li><li>word matching</li><li>result aggregation</li></ul><p>While data decomposition focuses on partitioning the set of pdf files
into chunks that can be processed concurrently.
The initial sequential implementation revealed that pdf files constitute
independent units of work, as analyzing one file does not depend on the
results of analyzing another, making them ideal candidates for parallel processing.</p><h2 id="coordination-and-synchronization-challenges" data-location="1.2">Coordination and synchronization challenges</h2><p>Despite the high degree of independence, several coordination
points require careful synchronization.
The shared counters (total files analyzed, pdfs found,
pdfs containing the target word) represent critical sections
that must be protected against race conditions when multiple threads
update them concurrently.
Additionally, the gui updates must be coordinated to ensure
consistent and accurate display of progress without overwhelming
the event dispatch thread.
The start, stop, suspend, resume controls introduce additional
complexity, requiring mechanisms to pause and resume worker threads
cooperatively while maintaining system state consistency.</p><div class="page-break" data-hidden=""></div><h1 id="solution-strategy-and-architecture" data-location="2">Solution strategy and architecture</h1><h2 id="highlevel-architecture" data-location="2.1">Highlevel architecture</h2><p>The project adopts a modular architecture that combines the Model-View-Controller 
pattern with the Strategy pattern to accommodate six distinct concurrency approaches while
maintaining code reusability and separation of concerns.</p><figure><pre class="mermaid fill-height">flowchart TD
    subgraph MVC[&quot;MVC Pattern&quot;]
        V[SearchView]
        C[SearchController]
        M[SearchModel]
    end
    
    subgraph Strategies[&quot;Strategy Pattern&quot;]
        S[PdfWordSearcher Interface]
        T1[Thread]
        T2[Virtual Thread]
        T3[Task Based]
        T4[Async Event]
        T5[Reactive]
        T6[Actor]
    end
    
    E[ExtractionEvent]
    
    V --&gt; C
    C --&gt; M
    M --&gt; V
    C --&gt; S
    
    S --&gt; T1
    S --&gt; T2
    S --&gt; T3
    S --&gt; T4
    S --&gt; T5
    S --&gt; T6
    
    T1 --&gt; E
    T2 --&gt; E
    T3 --&gt; E
    T4 --&gt; E
    T5 --&gt; E
    T6 --&gt; E
    
    E --&gt; M</pre></figure><h3 id="core-architecture-components" data-location="2.1.1">Core architecture components</h3><p>The application&rsquo;s structure consists of three primary MVC
components that remain consistent across all concurrency implementations:</p><ul><li><strong>SearchModel</strong>: Encapsulates the application state, including counters for analyzed files, pdf files found, and matches containing the target word. This model serves as the single source of truth and notifies observers of state changes</li><li><strong>SearchView</strong>: Provides the graphical user interface with input fields for directory path and search word, control buttons (start/stop/suspend/resume), and output boxes displaying real-time progress</li><li><strong>SearchController</strong>: Mediates between the view and model, handling user interactions and delegating work to the appropriate concurrency strategy implementation</li></ul><p>The ModelObserver interface implements the Observer pattern, enabling the view to react to model state changes without tight coupling, ensuring that gui updates remain synchronized with the underlying computational progress.</p><h3 id="strategy-pattern" data-location="2.1.2">Strategy pattern</h3><p>The core of this architecture lies in the strategies package,
which encapsulates each concurrency approach as an interchangeable implementation
of the PdfWordSearcher interface.
This design decision allows the controller to remain agnostic to the underlying concurrency
mechanism while supporting six fundamentally different approaches:</p><ul><li><strong>thread</strong>: Implements traditional multithreaded approach using custom monitors and thread pools</li><li><strong>virtual threads</strong>: Leverages Java virtual threads for lightweight concurrency</li><li><strong>task based</strong>: Utilizes Java Executors and Fork/Join framework with task decomposition</li><li><strong>async event</strong>: Employs Vertx event-loop architecture for asynchronous processing</li><li><strong>reactive programming</strong>: Applies RxJava reactive streams for data flow management</li><li><strong>actors</strong>: Uses Akka actor model for message-passing concurrency</li></ul><p>Each strategy package contains specialized components tailored to its concurrency model while adhering to a common interface,
ensuring seamless swapping between implementations.</p><h3 id="event-system" data-location="2.1.3">Event system</h3><p>The events package defines a unified event model (ExtractionEvent and ExtractionEventType)
that enables consistent communication between Model, Controller and View.
This abstraction allows different strategies to report progress using the same event types
regardless of their internal implementation details.
​</p><h3 id="supporting-infrastructure" data-location="2.1.4">Supporting infrastructure</h3><p>The project structure includes dedicated components for testing and validation:</p><ul><li>generator: Contains scripts and sample pdfs for creating test datasets with varying file counts and directory depths</li><li>pdfs: Houses multiple test scenarios ranging from small sets (3-10 files) to large-scale tests (50,000+ files) with both flat and recursive directory structures</li><li>jpf-workspace: Provides Java PathFinder integration for formal verification of concurrent properties in the thread based implementation</li></ul><p>This organizational structure ensures that each concurrency strategy can be developed,
tested, and analyzed independently while sharing common infrastructure components,
facilitating comparative performance analysis across all six approaches.</p><h2 id="thread-based-approach" data-location="2.2">Thread based approach</h2><p>The thread based implementation leverages traditional multithreading
principles with custom monitor synchronization to achieve optimal CPU
utilization while maintaining strict control over concurrency mechanisms.</p><figure><pre class="mermaid fill-height">flowchart TD
    Start([pdf Files List])
    Split{Partition N=CPU+1}
    W1[Worker 1 Chunk 1]
    W2[Worker 2 Chunk 2]
    W3[Worker N Chunk N]
    P1[Process pdfs Extract Match]
    P2[Process pdfs Extract Match]
    P3[Process pdfs Extract Match]
    U1[Update Model: increment pdfsWithWord]
    U2[Update Model: increment pdfsWithWord]
    U3[Update Model: increment pdfsWithWord]
    M((Monitor))
    Wait[Output Thread await]
    Signal[signal complete]
    Result([Final Count + Time])
    
    Start --&gt; Split
    Split --&gt; W1
    Split --&gt; W2
    Split --&gt; W3
    W1 --&gt; P1
    W2 --&gt; P2
    W3 --&gt; P3
    P1 --&gt; U1
    P2 --&gt; U2
    P3 --&gt; U3
    U1 --&gt; M
    U2 --&gt; M
    U3 --&gt; M
    M --&gt; Wait
    Wait --&gt; Signal
    Signal --&gt; Result</pre></figure><h3 id="thread-pool-size-strategy" data-location="2.2.1">Thread pool size strategy</h3><p>The solution dynamically determines the optimal number of worker threads based
on available CPU resources using the formula Nthreads = Ncpu + 1,
where Ncpu is obtained via <span class="codespan-content"><code>Runtime.getRuntime().availableProcessors()</code></span>.
This approach follows the established heuristic that a system with N processors
achieves optimal utilization with N+1 threads.</p><h3 id="work-partitioning-and-distribution" data-location="2.2.2">Work partitioning and distribution</h3><p>The ThreadPoolSearch class divides the list of pdf files into equal-sized chunks using a step-based partitioning strategy: step = numFiles / Nthreads.
Each Worker thread receives a contiguous range defined by start and end indices, processing files
independently without inter-worker communication. The final worker handles any remaining files due to integer division, ensuring all pdfs are processed.</p><h3 id="monitor-based-coordination" data-location="2.2.3">Monitor based Coordination</h3><p>The custom monitor class implements a synchronization mechanism using ReentrantLock
and Condition variables from java.util.concurrent.locks, adhering to the assignment
constraint of using only low-level concurrent utilities for monitor implementation.
The monitor maintains two critical pieces of state:</p><ul><li>count: Accumulates the total number of pdfs containing the target word across all workers.</li><li>numFiles: Tracks remaining unprocessed files, decremented as workers complete their chunks.</li></ul><p>Workers call <span class="codespan-content"><code>updateFoundFiles(analyzedFiles, filesFound)</code></span> upon completing their assigned chunk, which atomically updates both counters under mutex protection. When the last worker finishes (numFiles == 0),
the monitor signals the waiting Output thread via the workersFinished condition variable.</p><h3 id="worker-thread-implementation" data-location="2.2.4">Worker thread implementation</h3><p>Each worker thread <span class="codespan-content"><code>extends Thread</code></span> and processes its assigned file range by iterating through
pdf files, extracting text using Apache pdfBox&rsquo;s pdfTextStripper, and performing string matching.
The worker immediately updates the shared SearchModel when a match is found via <span class="codespan-content"><code>model.incCountPdfFilesWithWord()</code></span>,
enabling real-time updates.
After processing all assigned files, the worker reports its results to the monitor,
decoupling individual progress updates from final aggregation.</p><h3 id="output-thread-and-results-collection" data-location="2.2.5">Output thread and results collection</h3><p>The Output thread implements a separate waiting mechanism that blocks on the monitor&rsquo;s get()
method until all workers signal completion. This design separates result collection from
computation, allowing the main thread to remain responsive while workers execute in parallel.
The output thread also measures total execution time from job start to completion,
providing performance metrics.</p><figure><pre class="mermaid fill-height">classDiagram
    class PdfWordSearcher {
        &lt;&lt;interface&gt;&gt;
        +extractText(List~File~ pdfs, String word, SearchModel model)
    }
    
    class ThreadPoolSearch {
        +extractText(List~File~ files, String word, SearchModel model)
    }
    
    class Monitor {
        -int count
        -Lock mutex
        -Condition workersFinished
        -int numFiles
        -SearchModel model
        +Monitor(int numFiles, SearchModel model)
        +updateFoundFiles(int analyzedFiles, int filesFound)
        +get() int
    }
    
    class Worker {
        -Monitor cell
        -List~File~ files
        -int start
        -int end
        -String searchedWord
        -SearchModel model
        +Worker(Monitor cell, int start, int end, List~File~ files, String word, SearchModel model)
        +run()
        -containsWord(File pdf, String word) boolean
    }
    
    class Output {
        -Monitor cell
        -long startTime
        +Output(Monitor cell, long startTime)
        +run()
    }
    
    class SearchModel {
        +incCountPdfFilesWithWord()
    }
    
    PdfWordSearcher &lt;|.. ThreadPoolSearch
    ThreadPoolSearch ..&gt; Monitor : creates
    ThreadPoolSearch ..&gt; Worker : creates
    ThreadPoolSearch ..&gt; Output : creates
    Worker --&gt; Monitor : updates
    Worker --&gt; SearchModel : updates
    Output --&gt; Monitor : waits on
    Monitor --&gt; SearchModel : uses</pre></figure><div class="page-break" data-hidden=""></div><p></p><h2 id="virtual-threads" data-location="2.3">Virtual Threads</h2><p>The virtual thread implementation adopts a virtual thread per file strategy where each
pdf is processed by its own virtual thread.</p><h3 id="implementation-structure" data-location="2.3.1">Implementation Structure</h3><p>The solution creates a <strong>monitor</strong> to coordinate all virtual threads, initialized with the total number of files to process. A <strong>virtual thread executor</strong> manages the lifecycle of all worker threads automatically through Java&rsquo;s resource management. Additionally, a separate <strong>output thread</strong> is created but held in reserve until all worker threads begin their execution.</p><p>The processing logic iterates through the entire list of pdf files and submits each one as an independent task to the executor. For each file, a new virtual thread is spawned with a unique identifier for debugging purposes. Each virtual thread independently loads its assigned pdf, extracts the text content, searches for the target word, and reports whether a match was found to the shared monitor.
Once all tasks are submitted, the output thread begins execution and the main program waits for it to complete before returning</p><h3 id="monitor-synchronization" data-location="2.3.2">Monitor synchronization</h3><p>The monitor uses explicit lock and condition variable mechanisms rather than traditional synchronized blocks, which is essential to prevent virtual threads from being pinned to their carrier threads during blocking operations. When each thread completes processing its file, it calls a method that updates the match counter if the word was found, decrements the remaining work counter, and signals when all files have been processed. The output thread blocks on the monitor until it receives the completion signal, then retrieves and returns the final count.</p><p>During the computation, every time a new file contains the word, the model is updated.</p><p>This architecture exploits the lightweight nature of virtual threads to achieve massive parallelism, creating as many virtual threads as there are pdf files, without overwhelming system resources.</p><figure><pre class="mermaid fill-height">classDiagram
class PdfWordSearcher {
    &lt;&lt;interface&gt;&gt;
    +extractText(List~File~ pdfs, String word, SearchModel model)
}

class VirtualThreadSearcher {
    +extractText(List~File~ files, String word, SearchModel model)
    -containsWord(File pdf, String word) boolean
}

class Monitor {
    -int count
    -Lock mutex
    -Condition workersFinished
    -int numFiles
    -SearchModel model
    +Monitor(int numFiles, SearchModel model)
    +foundWord(boolean found)
    +get() int
}

class VirtualThreadExecutor {
    &lt;&lt;executor&gt;&gt;
    +submit(Runnable task)
    +close()
}

class WorkerThread {
    &lt;&lt;virtual thread&gt;&gt;
    +start(Runnable task)
}

class OutputThread {
    &lt;&lt;virtual thread&gt;&gt;
    +run()
}

class SearchModel {
    +setCountPdfFilesWithWord(int count)
}

PdfWordSearcher &lt;|.. VirtualThreadSearcher
VirtualThreadSearcher ..&gt; Monitor : creates
VirtualThreadSearcher ..&gt; VirtualThreadExecutor : uses
VirtualThreadSearcher ..&gt; OutputThread : creates
VirtualThreadExecutor ..&gt; WorkerThread : spawns N threads
WorkerThread --&gt; Monitor : reports to
WorkerThread --&gt; SearchModel : updates
OutputThread --&gt; Monitor : waits on
Monitor --&gt; SearchModel : updates</pre></figure><div class="page-break" data-hidden=""></div><h2 id="task-based-approach" data-location="2.4">Task based approach</h2><p>The task-based implementation uses Java&rsquo;s ForkJoin framework to decompose the problem hierarchically, mirroring the recursive structure of the directory tree itself.</p><h3 id="hierarchical-task-decomposition" data-location="2.4.1">Hierarchical task decomposition</h3><p>The solution begins by constructing a complete representation of the directory structure before processing begins. The tree representation recursively captures subdirectories and pdf files at each level, creating a hierarchical data structure that mirrors the file system. This upfront construction enables the ForkJoin framework to understand the complete workload structure and optimize task distribution.</p><p>The tree builder traverses each directory, classifying entries as either subdirectories (which are recursively processed) or pdf files (which are collected as leaf nodes). This separation allows the framework to spawn different task types: directory scanning tasks for structural traversal and word search tasks for actual file processing.</p><h3 id="forkjoin-execution-model" data-location="2.4.2">ForkJoin execution model</h3><p>The coordinator creates a ForkJoin pool and submits the root in the directory task, which initiates the recursive decomposition. Each directory scanning task examines its assigned directory node and performs a two phase forking strategy.</p><p>In the first phase, the task creates and forks child directory tasks for each subdirectory, enabling parallel exploration of the directory tree. In the second phase, it creates and forks word search tasks for each pdf file in the current directory. All forked tasks are collected in a list for subsequent joining.</p><p>After forking all subtasks, the directory task enters a joining phase where it waits for each child task to complete and accumulates their results. This fork-join pattern creates a recursive decomposition where work is divided (forked) down the tree and results are aggregated (joined) back up.</p><h3 id="leaf-word-search-task-process" data-location="2.4.3">Leaf (word search) task process</h3><p>Word search tasks represent the atomic units of computation in this approach. Each task receives a single pdf file reference, extracts its text content, searches for the target word, and returns either 1 for a match or 0 for no match. When a match is found, the task immediately updates the shared model to provide constant UI feedback</p><figure><pre class="mermaid fill-height">flowchart TD
Start([Start ForkJoinSearcher]) --&gt; Build[Build DirectoryTree&lt;br/&gt;from root directory]
Build --&gt; CreatePool[Create ForkJoinPool]
CreatePool --&gt; Submit[Submit Root DirectoryScanTask]

Submit --&gt; RootCompute[Compute: Root Directory]
RootCompute --&gt; RootFork[[Fork: Create Child Tasks]]

RootFork -.-&gt; SubDir1Task[DirectoryScanTask&lt;br/&gt;Subdirectory 1]
RootFork -.-&gt; SubDir2Task[DirectoryScanTask&lt;br/&gt;Subdirectory 2]
RootFork -.-&gt; PDF1Task[WordSearchTask&lt;br/&gt;PDF 1]
RootFork -.-&gt; PDF2Task[WordSearchTask&lt;br/&gt;PDF 2]
RootFork -.-&gt; PDF3Task[WordSearchTask&lt;br/&gt;PDF 3]

SubDir1Task --&gt; SubDir1Fork[[Fork: Subdirectory 1]]
SubDir1Fork -.-&gt; PDF4Task[WordSearchTask&lt;br/&gt;PDF 4]
SubDir1Fork -.-&gt; PDF5Task[WordSearchTask&lt;br/&gt;PDF 5]

SubDir2Task --&gt; SubDir2Fork[[Fork: Subdirectory 2]]
SubDir2Fork -.-&gt; PDF6Task[WordSearchTask&lt;br/&gt;PDF 6]
SubDir2Fork -.-&gt; PDF7Task[WordSearchTask&lt;br/&gt;PDF 7]

PDF1Task --&gt; Result1[Compute:&lt;br/&gt;Extract &amp; Search&lt;br/&gt;Return 0/1]
PDF2Task --&gt; Result2[Compute:&lt;br/&gt;Extract &amp; Search&lt;br/&gt;Return 0/1]
PDF3Task --&gt; Result3[Compute:&lt;br/&gt;Extract &amp; Search&lt;br/&gt;Return 0/1]
PDF4Task --&gt; Result4[Compute:&lt;br/&gt;Extract &amp; Search&lt;br/&gt;Return 0/1]
PDF5Task --&gt; Result5[Compute:&lt;br/&gt;Extract &amp; Search&lt;br/&gt;Return 0/1]
PDF6Task --&gt; Result6[Compute:&lt;br/&gt;Extract &amp; Search&lt;br/&gt;Return 0/1]
PDF7Task --&gt; Result7[Compute:&lt;br/&gt;Extract &amp; Search&lt;br/&gt;Return 0/1]

Result4 --&gt; Join2[[Join: Subdirectory 1]]
Result5 --&gt; Join2
Join2 --&gt; Sum2[Sum SubDir1 Results]

Result6 --&gt; Join3[[Join: Subdirectory 2]]
Result7 --&gt; Join3
Join3 --&gt; Sum3[Sum SubDir2 Results]

Result1 --&gt; RootJoin[[Join: Root Directory]]
Result2 --&gt; RootJoin
Result3 --&gt; RootJoin
Sum2 --&gt; RootJoin
Sum3 --&gt; RootJoin

RootJoin --&gt; Aggregate[Aggregate Total Count]
Aggregate --&gt; End([End])</pre></figure><div class="page-break" data-hidden=""></div><h2 id="async-event-approach" data-location="2.5">Async event approach</h2><p>The async event implementation uses the Vert.x framework, which provides an event loop architecture for non-blocking asynchronous processing.</p><h3 id="verticle-based-architecture" data-location="2.5.1">Verticle based architecture</h3><p>The solution creates a custom verticle, which serves as the deployable unit of concurrent execution in Vert.x. The main searcher class configures a Vert.x instance with a worker pool sized to match available CPU cores, then deploys the pdf search verticle onto this runtime.
The verticle encapsulates the entire search logic within its methods, receiving the list of pdf files, target word, and model reference through its constructor. When the verticle starts, it initiates the asynchronous processing pipeline.</p><h3 id="event-loop-and-worker-pool" data-location="2.5.2">Event loop and worker pool</h3><p>For each pdf file, the verticle submits a blocking task that extracts text and searches for the target word. These tasks execute on worker threads from the pool, preventing the event loop from blocking. Each blocking operation immediately returns a Future object representing the eventual completion of that task.</p><h3 id="future-composition-and-aggregation" data-location="2.5.3">Future Composition and aggregation</h3><p>All individual file processing futures are collected into a list as they are created. The framework then composes these futures using a composite future that completes only when all individual futures have finished.
When the composite future completes, a mapping operation iterates through all results, summing the match counts and updating the model with the final total. This composition is declarative, with success handlers attached to process results when they become available.</p><h3 id="non-blocking-result-handling" data-location="2.5.4">Non blocking result handling</h3><p>The result handling follows a callback based pattern where success handlers are registered to execute when futures complete. This approach ensures the event loop remains free to handle other events while waiting for blocking operations to finish. Timing information is captured at the start of processing and compared against completion time to measure total execution duration.</p><figure><pre class="mermaid fill-height">flowchart TD
Start([Start VertxAsyncSearcher]) --&gt; Config[Configure Vert.x&lt;br/&gt;Worker Pool Size = CPU cores]
Config --&gt; Deploy[Deploy PdfSearchVerticle]
Deploy --&gt; VerticleStart[Verticle.start invoked]

VerticleStart --&gt; SubmitFork[[Fork: Submit All Blocking Tasks]]

SubmitFork -.-&gt; Task1[Submit Blocking Task&lt;br/&gt;PDF 1 → Future 1]
SubmitFork -.-&gt; Task2[Submit Blocking Task&lt;br/&gt;PDF 2 → Future 2]
SubmitFork -.-&gt; TaskN[Submit Blocking Task&lt;br/&gt;PDF N → Future N]

Task1 --&gt; Worker1[Worker Thread Pool:&lt;br/&gt;Extract &amp; Search PDF 1]
Task2 --&gt; Worker2[Worker Thread Pool:&lt;br/&gt;Extract &amp; Search PDF 2]
TaskN --&gt; WorkerN[Worker Thread Pool:&lt;br/&gt;Extract &amp; Search PDF N]

Worker1 --&gt; Check1{Match&lt;br/&gt;found?}
Worker2 --&gt; Check2{Match&lt;br/&gt;found?}
WorkerN --&gt; CheckN{Match&lt;br/&gt;found?}

Check1 --&gt;|Yes| Update1[Update Model]
Check1 --&gt;|No| Return1[Return 0]
Update1 --&gt; Return1Matched[Return 1]

Check2 --&gt;|Yes| Update2[Update Model]
Check2 --&gt;|No| Return2[Return 0]
Update2 --&gt; Return2Matched[Return 1]

CheckN --&gt;|Yes| UpdateN[Update Model]
CheckN --&gt;|No| ReturnN[Return 0]
UpdateN --&gt; ReturnNMatched[Return 1]

Return1 --&gt; Complete1[Future 1 completes]
Return1Matched --&gt; Complete1
Return2 --&gt; Complete2[Future 2 completes]
Return2Matched --&gt; Complete2
ReturnN --&gt; CompleteN[Future N completes]
ReturnNMatched --&gt; CompleteN

Complete1 --&gt; JoinBar[[Join: Future.all Composite Future]]
Complete2 --&gt; JoinBar
CompleteN --&gt; JoinBar

JoinBar --&gt; Map[Map: Sum all results]
Map --&gt; Success[Success Handler:&lt;br/&gt;Update final count &amp; print time]
Success --&gt; End([End])</pre></figure><div class="page-break" data-hidden=""></div><h2 id="reactive-programming-approach" data-location="2.6">Reactive programming approach</h2><p>The reactive programming implementation uses RxJava to model pdf processing as a data stream.</p><h3 id="hot-observable-stream-creation" data-location="2.6.1">Hot observable stream creation</h3><p>The solution creates a hot observable stream by first defining a flowable source that emits processing results. The flowable is constructed using a custom emitter that iterates through all pdf files sequentially, processing each one and emitting integer values: 1 for files containing the target word, 0 otherwise.
The emitter handles the complete lifecycle: it processes all files in a loop, emits results as they become available, signals completion when all files are processed, and propagates any errors encountered during execution. A <strong>buffer backpressure strategy</strong> is configured to handle situations where the consumer cannot keep up with emitted items.
After creating the flowable, it is converted to a hot observable using the publish operator and immediately connected.</p><h3 id="flow-control" data-location="2.6.2">flow control</h3><p>The main processing pipeline applies a sequence of reactive operators to transform the stream. First, a backpressure buffer with a capacity of 5,000 items protects against overflow when the producer emits faster than the consumer can process.
The reduce operator aggregates all emitted values into a single sum, effectively counting total matches across all pdfs. This reduction happens asynchronously as values flow through the stream.
The pipeline concludes with a blocking subscription that waits for the final reduced value, executing success and error handlers when the stream completes.</p><p>Unlike the final aggregation performed by the reduce operator, the model is updated immediately within the emitter loop whenever a match is found. This update strategy provides real-time UI feedback through incremental model updates while the reduce operator handles final result computation.</p><figure><pre class="mermaid fill-height">flowchart TD
    Start([Start]) --&gt; Create[Create Flowable&lt;br/&gt;with Custom Emitter]
    Create --&gt; EmitterLoop{For each PDF&lt;br/&gt;in list}
    
    EmitterLoop --&gt;|Next PDF| Extract[Extract text from PDF&lt;br/&gt;containsWord]
    Extract --&gt; Match{Word&lt;br/&gt;found?}
    
    Match --&gt;|Yes| UpdateModel[Update Model&lt;br/&gt;incCountPdfFilesWithWord]
    Match --&gt;|No| EmitZero[Emit 0]
    UpdateModel --&gt; EmitOne[Emit 1]
    
    EmitOne --&gt; MoreFiles{More&lt;br/&gt;PDFs?}
    EmitZero --&gt; MoreFiles
    MoreFiles --&gt;|Yes| EmitterLoop
    MoreFiles --&gt;|No| Complete[Signal Complete]
    
    Complete --&gt; Publish[publish + connect&lt;br/&gt;Hot Observable]
    Publish --&gt; Buffer[onBackpressureBuffer&lt;br/&gt;capacity: 5000]
    Buffer --&gt; Reduce[reduce&lt;br/&gt;sum all emitted values]
    Reduce --&gt; Schedule[observeOn&lt;br/&gt;Schedulers.computation]
    Schedule --&gt; Subscribe[blockingSubscribe&lt;br/&gt;wait for final result]
    Subscribe --&gt; Print[Print total count + time]
    Print --&gt; End([End])</pre></figure><div class="page-break" data-hidden=""></div><h2 id="actor-approach" data-location="2.7">Actor approach</h2><p>The actor based implementation uses the Akka framework to model pdf processing as independent actors communicating through asynchronous message passing.</p><h3 id="actors" data-location="2.7.1">Actors</h3><p>The solution creates an Akka actor system named <span class="codespan-content"><code>PdfCounter</code></span> that serves as the runtime environment for all actors. Two actor types are instantiated: a single analyzer actor that processes all pdf files and maintains the match count, and a requester actor that retrieves the final result and terminates the system.</p><p>The analyzer actor is created first and receives its reference, which serves as its mailbox address for incoming messages. After all processing messages are sent, the requester actor is created and sent a query message to retrieve the accumulated count.</p><h3 id="messages" data-location="2.7.2">Messages</h3><p>The implementation defines two message types as immutable data classes. The processing message encapsulates a pdf file reference, the search word, and the model to update, bundling all necessary information for a single file analysis task. The query message is a simple marker class that signals the actor should respond with its current count.</p><p>Messages are sent using the tell method, which provides asynchronous delivery without blocking the sender. For processing messages, no sender reference is provided since no response is expected. For the query message, the requester actor&rsquo;s reference is provided so the analyzer knows where to send the final count.</p><h3 id="actor-behavior" data-location="2.7.3">Actor behavior</h3><p>The analyzer actor defines its behavior through a receive builder that pattern-matches incoming messages. When it receives a processing message, it executes the pdf text extraction, searches for the word, increments its internal count if a match is found, and updates the model.
When it receives a query message, it responds by sending its accumulated count back to the sender using the sender reference automatically captured from the incoming message context.</p><figure><pre class="mermaid fill-height">flowchart TD
Start([Start]) --&gt; CreateSystem[Create ActorSystem&lt;br/&gt;PdfCounter]
CreateSystem --&gt; CreateAnalyzer[Create PdfAnalyzerActor]

CreateAnalyzer --&gt; SendLoop{More pdfs?}
SendLoop --&gt;|Yes| SendMsg[Send PdfWordMessage&lt;br/&gt;to Analyzer]
SendMsg --&gt; SendLoop
SendLoop --&gt;|No| CreateReq[Create RequesterActor]

CreateReq --&gt; SendQuery[Send GetCount&lt;br/&gt;to Analyzer with&lt;br/&gt;Requester ref]

SendQuery --&gt; AnalyzerProcess

subgraph AnalyzerProcess[PdfAnalyzerActor Processing]
    ReceiveMsg{Receive&lt;br/&gt;Message}
    ReceiveMsg --&gt;|PdfWordMessage| Load[Load pdf &amp;&lt;br/&gt;Extract Text]
    Load --&gt; Search{Contains&lt;br/&gt;Word?}
    Search --&gt;|Yes| IncCount[Increment Count]
    Search --&gt;|No| Skip[Skip]
    IncCount --&gt; UpdateModel[Update Model]
    UpdateModel --&gt; NextMsg[Next Message]
    Skip --&gt; NextMsg
    NextMsg --&gt; ReceiveMsg
    
    ReceiveMsg --&gt;|GetCount| SendCount[Send Count&lt;br/&gt;to Requester]
end

SendCount --&gt; RequesterReceive

subgraph RequesterReceive[RequesterActor Processing]
    Receive[Receive Count]
    Receive --&gt; LogResult[Log Result]
    LogResult --&gt; Terminate[Terminate ActorSystem]
end

Terminate --&gt; End([End])</pre></figure><div class="page-break" data-hidden=""></div><h1 id="performance-and-correctness" data-location="3">Performance and correctness</h1><h2 id="benchmark-methodology" data-location="3.1">Benchmark methodology</h2><p>The benchmarks evaluate the six different strategies for pdf word search using a consistent testing framework. Each benchmark follows this protocol:</p><h3 id="setup" data-location="3.1.1">Setup</h3><ul><li>Warmup: before the execution on directories with less than 1000 files to minimize JIT compilation effects</li><li>Iterations: 7 executions per test to calculate average performance (time)</li><li>Baseline: sequential single threaded approach for speedup calculation</li><li>Hardware: benchmarks were run in MacBook M3 pro (12 cores)</li></ul><h3 id="testing-folders" data-location="3.1.2">Testing folders</h3><ul><li>Small: 3 with word out of 10 pdfs</li><li>Medium: 50 with word out of 100 pdfs(flat and recursive)</li><li>Medium: 0 with word out of 1000 pdfs</li><li>Large: 1001 with word out of 10000 pdfs (flat and recurisive)</li><li>Largest: 10000 with word out of 50000 pdfs</li></ul><h2 id="results" data-location="3.2">Results</h2><table id="table-3.1"><thead><tr><th>Strategy</th><th>Average Speedup</th><th>Performance Category</th></tr></thead><tbody><tr><td>ForkJoin</td><td>5.50</td><td>Best</td></tr><tr><td>Virtual Threads</td><td>3.18</td><td>Strong</td></tr><tr><td>Thread Pool</td><td>2.98</td><td>Good</td></tr><tr><td>Reactive (RxJava)</td><td>1.23</td><td>Minimal improvement</td></tr><tr><td>Async Event (Vert.x)</td><td>1.08</td><td>No benefits</td></tr><tr><td>Actor (Akka)</td><td>0.83</td><td>Slower than sequential</td></tr></tbody><caption class="caption-bottom" data-location="3.1" data-localized-kind="Table"></caption></table><h3 id="findings" data-location="3.2.1">Findings</h3><ul><li><p><strong>ForkJoin</strong>: delivered the best performance (5.50 average speedup) with exceptional results on recursive directory structures, achieving 22.71 speedup on one large recursive directory test, probably because the discovery strategy was different and more efficient from all the other approaches.</p></li><li><p><strong>Virtual Threads</strong>: excelled on small datasets (6.33 speedup on 3-10 files) due to low thread creation overhead, but performance degraded on larger datasets (1.91-2.71)</p></li><li><p><strong>Thread Pool</strong>: provided stable, predictable performance (2.5-3.7) across all dataset sizes, making it reliable for production use.</p></li><li><p><strong>Reactive, Async Event, Actor</strong>: performed poorly probably due to high framework initialization overhead that overwhelmed the actual work. The Actor model was actually slower than sequential execution on small datasets.</p></li></ul><h2 id="model-checking" data-location="3.3">Model Checking</h2><p>To verify the correctness of the concurrent implementations, model checking was applied to the Thread Pool strategy using Java PathFinder.</p><p>To use java PathFinder was used the lightweight environment provided, which includes a preconfigured JPF installation for JDK 8.
The ThreadPool strategy was compiled with JPF&rsquo;s custom classpath and executed with Precise race detector listener to check for data races.</p><h3 id="results" data-location="3.3.1">Results</h3><p>The verification completed successfully with no race conditions, deadlocks, or synchronization errors detected in the ThreadPool strategy. This confirms that the Monitor based synchronization pattern and worker thread coordination are correctly implemented, ensuring thread safe updates to shared state (file counts, pdf matches) across all possible execution scenarios.
Model checking provided formal verification that the concurrent design is correct, complementing the performance benchmarks by ensuring reliability alongside efficiency.</p>
</body>
</html>